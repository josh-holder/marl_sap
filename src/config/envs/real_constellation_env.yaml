env: "real_constellation_env"

env_args:
  num_planes: 10
  num_sats_per_plane: 10
  m: 300
  episode_step_limit: 90
  L: 3
  lambda_: 0.5
  bids_as_actions: null
  N: 10
  M: 10

# Scheme related arguments
cooperative_rewards: False

test_greedy: True
test_nepisode: 100
test_interval: 50000
log_interval: 50000
runner_log_interval: 10000
learner_log_interval: 10000
t_max: 2050000
use_wandb: False
wandb_run_name: null